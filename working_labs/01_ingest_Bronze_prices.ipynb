{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeccd6ba-424e-468f-9712-5b3b0686b1bb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importar Librerías"
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a777307-10b0-4320-a7f9-b43e3e096c2f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generar Headers"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "HEADERS = ['NO_CONTRATO', 'NO_LICITACION', 'GPO', 'GEN', 'ESP', 'DIF', 'VAR', 'CANT_MAX','SOLICITADO', 'PRECIO_NETO', 'RAZON_SOCIAL', 'FECHA_INICIO', 'FECHA_TERMINACION', ]\n",
    "\n",
    "xlsx_folder = os.path.abspath(os.path.join(\"..\", \"market_files\" ))\n",
    "\n",
    "# Conversión a conjunto para comparar la unión interna\n",
    "needed_headers = set(HEADERS)\n",
    "missing_summary = {}   # {xlsx_file: [missing_cols...]}\n",
    "ok_files = []          # files that contain ALL required headers\n",
    "\n",
    "# Obtener todos los archivos xlsx\n",
    "xls_files = sorted(\n",
    "    os.path.join(xlsx_folder, f)\n",
    "    for f in os.listdir(xlsx_folder)\n",
    "    if f.lower().endswith(\".xlsx\")\n",
    "    )\n",
    "\n",
    "# Generar un datafame con los encabezados necesarios \n",
    "df_bronze = pd.DataFrame()\n",
    "# Confirmar que los archivos tienen los headers necesarios. \n",
    "for xlsx_file in xls_files: \n",
    "    pdf = pd.read_excel(\n",
    "        xlsx_file,\n",
    "        dtype=str,\n",
    "        na_filter=False\n",
    "    )\n",
    "    file_headers = set(pdf.columns)\n",
    "    # Interseccion de headdrs\n",
    "    intersection = needed_headers & file_headers\n",
    "\n",
    "    # Confirmar que los headers necesarios están presentes. \n",
    "    if len(intersection) == len(needed_headers):\n",
    "        #Agregar la fecha del archivo basado en el prefijo\n",
    "        file_date_str = os.path.basename(xlsx_file).replace(\"IMSS_\", \"\").replace(\".xlsx\", \"\")\n",
    "        file_date = pd.to_datetime(file_date_str, format=\"%Y_%m\").replace(day=1)\n",
    "        headers_out = HEADERS + ['FILE_DATE']\n",
    "        pdf['FILE_DATE'] = file_date\n",
    "        # Concatenamos el dataframe\n",
    "        df_bronze = pd.concat([df_bronze, pdf.loc[:, headers_out]], ignore_index=True)\n",
    "    else:\n",
    "        missing = sorted(needed_headers - file_headers)\n",
    "        missing_summary[xlsx_file] = missing\n",
    "display(df_bronze.head(10))\n",
    "#df_bronze.limit(10).display()\n",
    "# Resumen\n",
    "print(f\"✅ OK los archivos tienen {len(HEADERS)} encabezados presentes): {len(ok_files)}\")\n",
    "if missing_summary:\n",
    "    print(f\"⚠️ Files with missing headers: {len(missing_summary)}\")\n",
    "\n",
    "\n",
    "headers_clean = df_bronze.columns.tolist() \n",
    "print(f\"✅ Headers extraídos exitosamente: {headers_clean[0:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f09fc54c-e5e4-41ee-a453-d37b0780fed2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Crear tabla Bronze e Ingestión"
    }
   },
   "outputs": [],
   "source": [
    "# Retiramos filas con valores ausentes\n",
    "data_pdf = df_bronze.dropna()\n",
    "# Creamos el dataframe de spark\n",
    "spark_df = spark.createDataFrame(data_pdf) \\\n",
    "                 .toDF(*headers_clean)\n",
    "\n",
    "# Guardamos la tabla Delta\n",
    "table = \"workspace.default.bronze_market_data\"\n",
    "spark_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(table)\n",
    "\n",
    "print(f\"✅ Tabla e ingestión completada: {table}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_Bronze_prices",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
