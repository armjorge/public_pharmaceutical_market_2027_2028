{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf5b59c-584b-4e20-905c-e64e5c881de9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Análisis Histórico de compras 2022-2028\n",
    "\n",
    "Integración con información de mercado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca003f0-c5fb-46f9-b272-297a0a206666",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "274f7d3a-926d-459c-83e6-351acf7c2470",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importar librerías"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, regexp_replace, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "284dc6c5-dcef-4b70-9ca5-d7894e297419",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tabla con claves y descripciones únicas"
    }
   },
   "outputs": [],
   "source": [
    "df_unique_products = spark.sql(\"\"\"\n",
    "    WITH all_claves AS (\n",
    "        SELECT DISTINCT clave FROM workspace.default.silver_2027_2028  WHERE clave IS NOT NULL\n",
    "        UNION\n",
    "        SELECT DISTINCT clave FROM workspace.default.silver_2025_2026  WHERE clave IS NOT NULL\n",
    "        UNION\n",
    "        SELECT DISTINCT clave FROM workspace.default.silver_2023_2024  WHERE clave IS NOT NULL\n",
    "        UNION\n",
    "        SELECT DISTINCT clave FROM workspace.default.silver_market_data  WHERE clave IS NOT NULL\n",
    "    ),\n",
    "    with_descriptions AS (\n",
    "        SELECT \n",
    "            ac.clave,\n",
    "            COALESCE(\n",
    "                t2728.descripcion,\n",
    "                t2526.descripcion,\n",
    "                t2324.descripcion,\n",
    "                'Descripción no localizada en compra consolidada'\n",
    "            ) AS descripcion\n",
    "        FROM all_claves ac\n",
    "        LEFT JOIN workspace.default.silver_2027_2028 t2728 ON ac.clave = t2728.clave\n",
    "        LEFT JOIN workspace.default.silver_2025_2026 t2526 ON ac.clave = t2526.clave\n",
    "        LEFT JOIN workspace.default.silver_2023_2024 t2324 ON ac.clave = t2324.clave\n",
    "    )\n",
    "    SELECT DISTINCT clave, descripcion\n",
    "    FROM with_descriptions\n",
    "\"\"\")\n",
    "\n",
    "# Guardamos la tabla Delta\n",
    "table = \"workspace.default.gold_unique_products\"\n",
    "\n",
    "df_unique_products.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(table)\n",
    "\n",
    "# Establecer clave como NOT NULL y luego agregar primary key\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ALTER COLUMN clave SET NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Optimizar la tabla y establecer la primary key\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ADD CONSTRAINT golden_unique_products_pk PRIMARY KEY (clave)\n",
    "\"\"\")\n",
    "\n",
    "# Optimizar la tabla para mejorar el rendimiento de lecturas\n",
    "spark.sql(f\"OPTIMIZE {table}\")\n",
    "\n",
    "# Z-ordering por clave para consultas más rápidas\n",
    "spark.sql(f\"OPTIMIZE {table} ZORDER BY (clave)\")\n",
    "\n",
    "print(f\"✅ Tabla Golden completada y optimizada: {table}\")\n",
    "print(f\"   - Primary Key: clave\")\n",
    "print(f\"   - Filas totales: {df_unique_products.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3918b3d6-f7d0-470a-a240-c3a629d45cc1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Máximos históricos para cada clave en columnas separadas"
    }
   },
   "outputs": [],
   "source": [
    "df_max_per_year = spark.sql(\"\"\" \n",
    "    SELECT\n",
    "    cl.clave,\n",
    "    cl.descripcion,\n",
    "    CAST(COALESCE(tab2023.totales_max, 0) AS DOUBLE) AS max_2023_2024,\n",
    "    CAST(COALESCE(tab2025.totales_max, 0) AS DOUBLE) AS max_2025_2026,\n",
    "    CAST(COALESCE(tab2027.totales_max, 0) AS DOUBLE) AS max_2027_2028\n",
    "    FROM workspace.default.gold_unique_products cl\n",
    "    FULL OUTER JOIN workspace.default.silver_2023_2024 tab2023\n",
    "    ON cl.clave = tab2023.clave\n",
    "    FULL OUTER JOIN workspace.default.silver_2025_2026 tab2025\n",
    "    ON cl.clave = tab2025.clave\n",
    "    FULL OUTER JOIN workspace.default.silver_2027_2028 tab2027\n",
    "    ON cl.clave = tab2027.clave\n",
    "    ORDER BY\n",
    "    cl.clave;\n",
    "    \"\"\")\n",
    "\n",
    "# Guardamos la tabla Delta\n",
    "table = \"workspace.default.gold_maximum_historics\"\n",
    "\n",
    "df_max_per_year.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(table)\n",
    "\n",
    "# Establecer clave como NOT NULL y luego agregar primary key\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ALTER COLUMN clave SET NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Optimizar la tabla y establecer la primary key\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ADD CONSTRAINT golden_max_per_year_pk PRIMARY KEY (clave)\n",
    "\"\"\")\n",
    "\n",
    "# Optimizar la tabla para mejorar el rendimiento de lecturas\n",
    "spark.sql(f\"OPTIMIZE {table}\")\n",
    "\n",
    "# Z-ordering por clave para consultas más rápidas\n",
    "spark.sql(f\"OPTIMIZE {table} ZORDER BY (clave)\")\n",
    "\n",
    "print(f\"✅ Tabla Golden completada y optimizada: {table}\")\n",
    "print(f\"   - Primary Key: clave\")\n",
    "print(f\"   - Filas totales: {df_max_per_year.count()}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08254f23-a3ed-4726-8d62-dfa0a2f1d203",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tabla con Institución desglosada"
    }
   },
   "outputs": [],
   "source": [
    "df_unpivoted2023_2024 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        clave,\n",
    "        \"CC 2023-2024\" AS comprac,\n",
    "        institucion,\n",
    "        totales_max\n",
    "    FROM workspace.default.silver_2023_2024\n",
    "    UNPIVOT (\n",
    "        max_value FOR institucion IN (\n",
    "            imss_max,\n",
    "            imss_bienestar_max,\n",
    "            issste_max,\n",
    "            ccinshae_max,\n",
    "            sedena_max,\n",
    "            semar_max,\n",
    "            guardia_nacional_max,\n",
    "            oadprs_max,\n",
    "            salud_spps_max\n",
    "        )\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "df_unpivoted2025_2026 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        clave,\n",
    "        \"CC 2025-2026\" AS comprac,\n",
    "        \"No determinada\" AS institucion,\n",
    "        totales_max\n",
    "    FROM workspace.default.silver_2025_2026\n",
    "    \"\"\")\n",
    "\n",
    "df_unpivoted2027_2028 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        clave,\n",
    "        \"CC 2027-2028\" AS comprac,\n",
    "        institucion,\n",
    "        totales_max\n",
    "    FROM workspace.default.silver_2027_2028\n",
    "    UNPIVOT (\n",
    "        max_value FOR institucion IN (\n",
    "            imss_max,\n",
    "            issste_max,\n",
    "            pemex_max,\n",
    "            imss_bienestar_max,\n",
    "            ccinshae_max,\n",
    "            salud_spps_max\n",
    "        )\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "df_combined = df_unpivoted2023_2024 \\\n",
    "    .unionAll(df_unpivoted2027_2028) \\\n",
    "    .unionAll(df_unpivoted2025_2026) \\\n",
    "    .withColumn(\"institucion\", regexp_replace(col(\"institucion\"), \"_max$\", \"\"))\n",
    "\n",
    "# Guardamos la tabla Delta\n",
    "table = \"workspace.default.gold_contribucion_p_institucion\"\n",
    "\n",
    "df_combined.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(table)\n",
    "\n",
    "# Establecer clave como NOT NULL y luego agregar primary key\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ALTER COLUMN clave SET NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ALTER COLUMN comprac SET NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Optimizar la tabla y establecer la primary key\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {table}\n",
    "    ADD CONSTRAINT golden_contr_por_inst_pk PRIMARY KEY (clave, comprac)\n",
    "\"\"\")\n",
    "\n",
    "# Optimizar la tabla para mejorar el rendimiento de lecturas\n",
    "spark.sql(f\"OPTIMIZE {table}\")\n",
    "\n",
    "# Z-ordering por clave para consultas más rápidas\n",
    "spark.sql(f\"OPTIMIZE {table} ZORDER BY (clave)\")\n",
    "\n",
    "print(f\"✅ Tabla Golden completada y optimizada: {table}\")\n",
    "print(f\"   - Primary Key: clave, comprac\")\n",
    "print(f\"   - Filas totales: {df_combined.count()}\")\n",
    "\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5563698070427518,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_gold_purchases_2023_2028",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
